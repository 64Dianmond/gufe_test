import json
import os
import re
from openai import OpenAI
from dotenv import load_dotenv
from cal import SentencingCalculator, SENTENCING_TOOLS, execute_tool_call

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()


class SentencingPredictor:
    """
    ä¸€ä¸ªåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„æ³•å¾‹é‡åˆ‘é¢„æµ‹å™¨ã€‚
    é‡‡ç”¨"æå–-æ³¨å…¥-è®¡ç®—"çš„ä¸‰æ­¥æ··åˆæ³•ï¼Œå¹¶é›†æˆäº†æƒå¨çš„ã€åˆ†å±‚çš„é‡åˆ‘è®¡ç®—è§„åˆ™ã€‚
    æ”¯æŒå·¥å…·è°ƒç”¨ï¼Œä½¿ç”¨ä¸“ä¸šè®¡ç®—å™¨è¿›è¡Œç²¾ç¡®çš„åˆ‘æœŸè®¡ç®—ã€‚
    """

    def __init__(self):
        """
        åˆå§‹åŒ–å®¢æˆ·ç«¯å’Œæ¨¡å‹é…ç½®ã€‚
        """
        self.client = OpenAI(
            api_key=os.getenv("OPENAI_API_KEY"),
            base_url=os.getenv("OPENAI_BASE_URL")
        )
        self.model_name = os.getenv("OPENAI_MODEL", "qwen-max")
        self.temperature_task1 = 1.0  # Task1ä½¿ç”¨è¾ƒé«˜æ¸©åº¦ä»¥å¢åŠ å¤šæ ·æ€§
        self.temperature_task2 = 0.1  # Task2ä½¿ç”¨è¾ƒä½æ¸©åº¦ä»¥ç¡®ä¿ç¨³å®šæ€§
        self.max_tokens = 8192

    def identify_crime_type(self, defendant_info, case_description):
        """
        å¢å¼ºç‰ˆçš„ç½ªåè¯†åˆ«å‡½æ•°ã€‚
        ä¼˜å…ˆä»æŒ‡æ§ä¸­è¯†åˆ«,å…¶æ¬¡é€šè¿‡å…³é”®è¯åŒ¹é…ã€‚
        """
        text = defendant_info + case_description
        text = text.replace(" ", "").replace("\n", "")

        # 1. ä¼˜å…ˆåŒ¹é…æŒ‡æ§ç½ªå,è¿™æ˜¯æœ€å‡†ç¡®çš„æ–¹å¼
        charge_match = re.search(r'(å› æ¶‰å«Œ|æŒ‡æ§çŠ¯)(.*?)ç½ª', text)
        if charge_match:
            crime = charge_match.group(2)
            if "ç›—çªƒ" in crime: return "ç›—çªƒç½ª"
            if "æ•…æ„ä¼¤å®³" in crime: return "æ•…æ„ä¼¤å®³ç½ª"
            if "è¯ˆéª—" in crime: return "è¯ˆéª—ç½ª"

        # 2. å¦‚æœæŒ‡æ§ä¸æ˜ç¡®,ä½¿ç”¨å…³é”®è¯ä½œä¸ºå¤‡ç”¨æ–¹æ¡ˆ
        theft_keywords = ["ç›—çªƒ", "çªƒå–", "æ‰’çªƒ", "ç›—èµ°"]
        injury_keywords = ["æ•…æ„ä¼¤å®³", "æ®´æ‰“", "æ‰“ä¼¤", "è½»ä¼¤", "é‡ä¼¤"]
        fraud_keywords = ["è¯ˆéª—", "éª—å–", "è™šæ„äº‹å®"]

        if any(k in text for k in theft_keywords): return "ç›—çªƒç½ª"
        if any(k in text for k in injury_keywords): return "æ•…æ„ä¼¤å®³ç½ª"
        if any(k in text for k in fraud_keywords): return "è¯ˆéª—ç½ª"

        # 3. é»˜è®¤å›é€€,æ ¹æ®æ•°æ®é›†çš„å¤šæ•°ç½ªåæ¥å®š,æ­¤å¤„ä»¥ç›—çªƒç½ªä¸ºä¾‹
        return "ç›—çªƒç½ª"

    # def extract_region(self, defendant_info, case_description):
    #     """
    #     ä»æ¡ˆä»¶ä¿¡æ¯ä¸­æå–åœ°åŒºä¿¡æ¯
    #     """
    #     text = defendant_info + case_description
    #     # å¸¸è§çš„åœ°åŒºå…³é”®è¯
    #     regions = ["åŒ—äº¬", "ä¸Šæµ·", "å¤©æ´¥", "é‡åº†", "æ²³åŒ—", "å±±è¥¿", "è¾½å®", "å‰æ—",
    #               "é»‘é¾™æ±Ÿ", "æ±Ÿè‹", "æµ™æ±Ÿ", "å®‰å¾½", "ç¦å»º", "æ±Ÿè¥¿", "å±±ä¸œ", "æ²³å—",
    #               "æ¹–åŒ—", "æ¹–å—", "å¹¿ä¸œ", "æµ·å—", "å››å·", "è´µå·", "äº‘å—", "é™•è¥¿",
    #               "ç”˜è‚ƒ", "é’æµ·", "å°æ¹¾", "å†…è’™å¤", "å¹¿è¥¿", "è¥¿è—", "å®å¤", "æ–°ç–†",
    #               "é¦™æ¸¯", "æ¾³é—¨"]
    #
    #     # å¸¸è§çš„åŸå¸‚å…³é”®è¯
    #     cities = ["æ±Ÿé—¨", "æ·±åœ³", "å¹¿å·", "ç æµ·", "ä½›å±±", "ä¸œè", "ä¸­å±±", "æ­å·",
    #              "å®æ³¢", "æ¸©å·", "å˜‰å…´", "ç»å…´", "å°å·", "ä¹‰ä¹Œ", "å—äº¬", "è‹å·",
    #              "æ— é”¡", "å¸¸å·", "å¾å·", "æµå—", "é’å²›", "çƒŸå°", "æ½åŠ", "å¤§è¿",
    #              "æ²ˆé˜³", "å“ˆå°”æ»¨", "é•¿æ˜¥", "æˆéƒ½", "è¥¿å®‰", "æ­¦æ±‰", "é•¿æ²™", "ç¦å·",
    #              "å¦é—¨", "è´µé˜³", "æ˜†æ˜", "å—å®", "çŸ³å®¶åº„", "å¤ªåŸ", "å—æ˜Œ", "åˆè‚¥",
    #              "éƒ‘å·", "æµ·å£", "ä¹Œé²æœ¨é½", "å‘¼å’Œæµ©ç‰¹", "é“¶å·", "è¥¿å®", "æ‹‰è¨", "å…°å·"]
    #
    #     # å…ˆå°è¯•æŸ¥æ‰¾çœä»½
    #     for region in regions:
    #         if region in text:
    #             return region
    #
    #     # å¦‚æœæ²¡æœ‰æ‰¾åˆ°çœä»½ï¼Œå°è¯•æŸ¥æ‰¾åŸå¸‚
    #     for city in cities:
    #         if city in text:
    #             return city
    #
    #     # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ˜ç¡®çš„åœ°åŒºï¼Œè¿”å›é»˜è®¤å€¼
    #     return "default"

    def build_prompt_task1_authoritative(self, defendant_info, case_description):
        """
        æ„å»ºæƒå¨ç‰ˆçš„é‡åˆ‘æƒ…èŠ‚æå–Prompt (Task 1)ã€‚
        Promptå†…å®¹ä¸¥æ ¼ä¾æ®å®˜æ–¹é‡åˆ‘æŒ‡å¯¼æ„è§ä¸­çš„æƒ…èŠ‚åˆ†ç±»ã€‚
        """
        crime_type = self.identify_crime_type(defendant_info, case_description)

        prompt = f"""ä½ æ˜¯ä¸€ä½æå…¶ä¸¥è°¨çš„åˆ‘äº‹æ³•å®˜,ä»»åŠ¡æ˜¯ä¾æ®ã€Šä¸­åäººæ°‘å…±å’Œå›½åˆ‘æ³•ã€‹åŠç›¸å…³é‡åˆ‘æŒ‡å¯¼æ„è§,ä»æ¡ˆæƒ…ä¸­æå–æ‰€æœ‰å¯¹é‡åˆ‘æœ‰å½±å“çš„å…³é”®æƒ…èŠ‚ã€‚

**é‡è¦æç¤º:** æœ¬ä»»åŠ¡å°†æ ¹æ®F1å€¼è¿›è¡Œè¯„åˆ†ï¼ŒF1å€¼æ˜¯ç²¾ç¡®ç‡(Precision)å’Œå¬å›ç‡(Recall)çš„è°ƒå’Œå¹³å‡æ•°ã€‚è¿™æ„å‘³ç€ä½ éœ€è¦åœ¨ç¡®ä¿æå–å‡†ç¡®æ€§çš„åŒæ—¶ï¼Œå°½å¯èƒ½å®Œæ•´åœ°æå–æ‰€æœ‰ç›¸å…³æƒ…èŠ‚ã€‚é”™è¯¯æå–ä¼šåŒæ—¶é™ä½ç²¾ç¡®ç‡å’Œå¬å›ç‡ï¼Œå› æ­¤è¯·ä¼˜å…ˆç¡®ä¿å‡†ç¡®æ€§ã€‚

**æ¡ˆä»¶ä¿¡æ¯:**
è¢«å‘Šäººä¿¡æ¯:{defendant_info}
æ¡ˆæƒ…æè¿°:{case_description}

**æœ¬æ¡ˆç½ªå(åˆæ­¥åˆ¤æ–­):** {crime_type}

**æå–æ€»è¦æ±‚:**
- **å¹³è¡¡å‡†ç¡®æ€§å’Œå®Œæ•´æ€§**: ä¼˜å…ˆç¡®ä¿æå–æƒ…èŠ‚çš„å‡†ç¡®æ€§ï¼Œå®å¯å°‘æå–ä¹Ÿä¸è¦æå–é”™è¯¯çš„æƒ…èŠ‚ï¼Œå› ä¸ºé”™è¯¯æå–ä¼šåŒæ—¶é™ä½ç²¾ç¡®ç‡å’Œå¬å›ç‡ã€‚
- **å¤„ç†è¾¹ç•Œæƒ…å†µ**: å¯¹äºæ¨¡ç³Šæˆ–ä¸ç¡®å®šçš„æƒ…èŠ‚ï¼Œåªæœ‰åœ¨æœ‰æ˜ç¡®è¯æ®æ”¯æŒæ—¶æ‰æå–ï¼Œé¿å…çŒœæµ‹æ€§æå–ã€‚

---
**è¯·æŒ‰ç…§ä»¥ä¸‹åˆ†ç±»å’ŒæŒ‡å¼•è¿›è¡Œæå–:**

**ä¸€ã€ çŠ¯ç½ªæ„æˆä¸åŸºæœ¬äº‹å®æƒ…èŠ‚ (å†³å®šé‡åˆ‘èµ·ç‚¹å’ŒåŸºå‡†åˆ‘)**
- **çŠ¯ç½ªæ•°é¢/åæœ**: å¿…é¡»æ˜ç¡®ä¸º **"ç›—çªƒ/è¯ˆéª—é‡‘é¢æ—¢é‚XXå…ƒ"** æˆ– **"æ•…æ„ä¼¤å®³è‡´Xäººè½»ä¼¤/é‡ä¼¤Xçº§"**ã€‚
- **æ•°é¢/åæœæ¡£æ¬¡**: å¿…é¡»æ˜ç¡®æ ‡æ³¨ **"ç›—çªƒ/è¯ˆéª—æ•°é¢è¾ƒå¤§/å·¨å¤§/ç‰¹åˆ«å·¨å¤§"**ã€‚
- **çŠ¯ç½ªæ‰‹æ®µ/æ–¹å¼**: æå–ç‰¹æ®Šæ‰‹æ®µ,å¦‚ **"å…¥æˆ·ç›—çªƒ"ã€"æºå¸¦å‡¶å™¨ç›—çªƒ"ã€"æ‰’çªƒ"ã€"ç”µä¿¡ç½‘ç»œè¯ˆéª—"** ç­‰ã€‚
- **çŠ¯ç½ªæ¬¡æ•°**: å¦‚ **"å¤šæ¬¡ç›—çªƒ"**ã€‚

**äºŒã€ æ³•å®šä»é‡ã€ä»è½»ã€å‡è½»å¤„ç½šæƒ…èŠ‚ (å¿…é¡»ä¾æ³•è°ƒèŠ‚)**
- **ç´¯çŠ¯**: é‡ç‚¹æ ¸æŸ¥è¢«å‘Šäººä¿¡æ¯ä¸­çš„å‰ç§‘è®°å½•,åˆ¤æ–­æ˜¯å¦æ„æˆç´¯çŠ¯(ä¸€èˆ¬ä¸ºæœ‰æœŸå¾’åˆ‘æ‰§è¡Œå®Œæ¯•æˆ–èµ¦å…ä»¥å,äº”å¹´ä»¥å†…å†çŠ¯åº”å½“åˆ¤å¤„æœ‰æœŸå¾’åˆ‘ä»¥ä¸Šåˆ‘ç½šä¹‹ç½ª)ã€‚
  - åŒ…æ‹¬: **"ä¸€èˆ¬ç´¯çŠ¯"**ã€**"ç‰¹åˆ«ç´¯çŠ¯"**
- **è‡ªé¦–**: é‡ç‚¹æ ¸æŸ¥å½’æ¡ˆæ–¹å¼,å¦‚ä¸»åŠ¨æŠ•æ¡ˆ,æˆ–"å½¢è¿¹å¯ç–‘,ç»ç›˜é—®ã€æ•™è‚²å,ä¸»åŠ¨äº¤ä»£äº†å¸æ³•æœºå…³æœªæŒæ¡çš„ç½ªè¡Œ","åœ¨æ¡ˆå‘åœ°ç­‰å€™å¤„ç½®"ç­‰å‡å¯èƒ½æ„æˆè‡ªé¦–ã€‚
  - åŒ…æ‹¬: **"ä¸€èˆ¬è‡ªé¦–"**ã€**"ç‰¹æ®Šè‡ªé¦–"**
- **ç«‹åŠŸ**: æ˜¯å¦æœ‰æ£€ä¸¾ã€æ­å‘ä»–äººçŠ¯ç½ªè¡Œä¸º,ç»æŸ¥è¯å±å®ç­‰æƒ…å†µã€‚
  - åŒ…æ‹¬: **"ä¸€èˆ¬ç«‹åŠŸ"**ã€**"é‡å¤§ç«‹åŠŸ"**
- **æœªæˆå¹´äººçŠ¯ç½ª**: è¢«å‘ŠäººçŠ¯ç½ªæ—¶æ˜¯å¦å·²æ»¡åå››å‘¨å²ä¸æ»¡åå…«å‘¨å²ã€‚
  - åŒ…æ‹¬: **"æœªæˆå¹´äººçŠ¯ç½ª"**ã€**"å·²æ»¡åå››å‘¨å²ä¸æ»¡åå…­å‘¨å²"**
- **ä»çŠ¯/èƒä»çŠ¯**: åœ¨å…±åŒçŠ¯ç½ªä¸­çš„ä½œç”¨ã€‚
  - åŒ…æ‹¬: **"ä»çŠ¯"**ã€**"èƒä»çŠ¯"**
- **çŠ¯ç½ªé¢„å¤‡/ä¸­æ­¢/æœªé‚**ã€‚
  - åŒ…æ‹¬: **"çŠ¯ç½ªé¢„å¤‡"**ã€**"çŠ¯ç½ªä¸­æ­¢"**ã€**"çŠ¯ç½ªæœªé‚"**
- **å…¶ä»–æ³•å®šæƒ…èŠ‚**:
  - **"è®¤ç½ªè®¤ç½š"**
  - **"å¦ç™½"**
  - **"ç²¾ç¥çŠ¶æ€ï¼šé™åˆ¶åˆ‘äº‹è´£ä»»èƒ½åŠ›"**
  - **"å·²æ»¡ä¸ƒåäº”å‘¨å²çš„äººçŠ¯ç½ª"**
  - **"é˜²å«è¿‡å½“"**
  - **"åˆè‹åˆå“‘çš„äººçŠ¯ç½ª"**
  - **"ç›²äººçŠ¯ç½ª"**
  - **"ä¸è¢«å®³æ–¹è¾¾æˆå’Œè§£åè®®"**

**ä¸‰ã€ é…Œå®šä»é‡ã€ä»è½»å¤„ç½šæƒ…èŠ‚ (å¯ä»¥é…Œæƒ…è°ƒèŠ‚)**
- **è¯ˆéª—ç‰¹å®šå¯¹è±¡/æ¬¾ç‰©**: 
  - **"è¯ˆéª—æ•‘ç¾ã€æŠ¢é™©ã€é˜²æ±›ã€ä¼˜æŠšã€æ‰¶è´«ã€ç§»æ°‘ã€æ•‘æµã€åŒ»ç–—ç­‰æ¬¾ç‰©"**
  - **"ä»¥èµˆç¾åä¹‰è¯ˆéª—"**
  - **"è¯ˆéª—æ®‹ç–¾äººã€è€å¹´äººæˆ–è€…ä¸§å¤±åŠ³åŠ¨èƒ½åŠ›äºº"**
- **ä¸¥é‡åæœ**: 
  - **"é€ æˆè¢«å®³äººè‡ªæ€ã€ç²¾ç¥å¤±å¸¸æˆ–è€…å…¶ä»–ä¸¥é‡åæœ"**
  - **"æƒ¯çŠ¯æˆ–è€…æµçªœä½œæ¡ˆï¼Œå±å®³ä¸¥é‡"**
- **é€€èµƒ/é€€èµ”/èµ”å¿**: æ˜¯å¦é€€è¿˜èµƒæ¬¾èµƒç‰©,æˆ–èµ”å¿è¢«å®³äººç»æµæŸå¤±ã€‚å¿…é¡»é‡åŒ–,å¦‚ **"é€€èµ”XXå…ƒ"**ã€‚
  - åŒ…æ‹¬: **"é€€èµƒé€€èµ”"**ã€**"å½’æ¡ˆå‰è‡ªåŠ¨å°†èµƒç‰©å½’è¿˜è¢«å®³äºº"**ã€**"è¯ˆéª—è¿‘äº²å±è´¢ç‰©"**
- **å–å¾—è°…è§£**: æ˜¯å¦å–å¾—äº†è¢«å®³äººçš„ä¹¦é¢æˆ–å£å¤´è°…è§£ã€‚
  - åŒ…æ‹¬: **"è¢«å®³äººè°…è§£"**ã€**"åˆ‘äº‹å’Œè§£"**
- **å‰ç§‘**: ä¸æ„æˆç´¯çŠ¯,ä½†æœ‰çŠ¯ç½ªè®°å½•ã€‚
  - åŒ…æ‹¬: **"æœ‰å‰ç§‘"**
- **å…¶ä»–é…Œå®šæƒ…èŠ‚**:
  - **"æ²¡æœ‰å‚ä¸åˆ†èµƒæˆ–è€…è·èµƒè¾ƒå°‘ä¸”ä¸æ˜¯ä¸»çŠ¯"**
  - **"é‚»é‡Œçº çº·"**
  - **"å®¶åº­çŸ›ç›¾"**
  - **"è¢«å®³äººè¿‡é”™"** 
  - **"æŒ¥éœè¯ˆéª—æ‰€å¾—ç‰©ï¼Œå¯¼è‡´æ— æ³•è¿”è¿˜"**

---
**è¾“å‡ºæ ¼å¼:**
åªè¾“å‡ºä¸€ä¸ªJSONæ•°ç»„,åŒ…å«æ‰€æœ‰æå–åˆ°çš„æƒ…èŠ‚å­—ç¬¦ä¸²ã€‚ä¸è¦ä»»ä½•é‡åˆ‘æƒ…èŠ‚è§£é‡Šæˆ–Markdownæ ‡è®°ã€‚
- **ä¸¥æ ¼éµå®ˆJSONæ ¼å¼**: è¾“å‡ºå¿…é¡»æ˜¯æœ‰æ•ˆçš„JSONæ•°ç»„æ ¼å¼ï¼Œå¯ä»¥è¢«ç›´æ¥è§£æã€‚
- **ä»…åŒ…å«ç¡®å®šçš„æƒ…èŠ‚**: ä¸è¦åŒ…å«ä»»ä½•ä½ ä¸ç¡®å®šçš„æƒ…èŠ‚ã€‚
- **é¿å…é‡å¤**: ç¡®ä¿æ•°ç»„ä¸­æ²¡æœ‰é‡å¤çš„æƒ…èŠ‚ã€‚

**ç¤ºä¾‹({crime_type}):"""
        
        if crime_type == "è¯ˆéª—ç½ª":
            prompt += """
["è¯ˆéª—é‡‘é¢æ—¢é‚3631å…ƒ", "è¯ˆéª—æ•°é¢è¾ƒå¤§", "ä¸€èˆ¬ç´¯çŠ¯", "å¦ç™½", "é€€èµƒé€€èµ”", "è¢«å®³äººè°…è§£çš„"]
"""
        else:
            prompt += """
["ç›—çªƒé‡‘é¢æ—¢é‚3631å…ƒ", "ç›—çªƒæ•°é¢è¾ƒå¤§", "æ‰’çªƒ", "ç´¯çŠ¯", "å¦ç™½"]
"""
        return prompt

    def build_prompt_task2_with_tools(self, sentencing_factors):
        factors_str = "\n- ".join(sentencing_factors)

        prompt = f"""ä½ æ˜¯ä¸€ä½ç²¾é€šé‡åˆ‘è®¡ç®—çš„åˆ‘äº‹æ³•å®˜ã€‚ä½ å¿…é¡»ä½¿ç”¨æä¾›çš„ä¸“ä¸šè®¡ç®—å™¨å·¥å…·è¿›è¡Œç²¾ç¡®è®¡ç®—ï¼Œä¸¥æ ¼éµå¾ªé‡åˆ‘è§„èŒƒåŒ–çš„åˆ†å±‚è®¡ç®—è§„åˆ™ã€‚

    **å·²è®¤å®šçš„é‡åˆ‘æƒ…èŠ‚:**
    - {factors_str}

    **ã€é‡è¦ã€‘è°ƒèŠ‚æ¯”ä¾‹ç¡®å®šæ€§åŸåˆ™:**
    æœ¬ç³»ç»Ÿé‡‡ç”¨**å›ºå®šåˆ†çº§ç³»æ•°è¡¨**ï¼Œç¡®ä¿è®¡ç®—ç»“æœçš„ç¨³å®šæ€§å’Œå¯é¢„æµ‹æ€§ã€‚ä½ éœ€è¦ï¼š
    1. ä»”ç»†åˆ†ææ¯ä¸ªæƒ…èŠ‚çš„å…·ä½“æè¿°ï¼ˆå¦‚å¹´é¾„ã€ä½œç”¨å¤§å°ã€æŠ•æ¡ˆæ–¹å¼ç­‰ï¼‰
    2. æ ¹æ®æè¿°çš„å…·ä½“æƒ…å†µï¼Œé€‰æ‹©å¯¹åº”çš„å›ºå®šç³»æ•°
    3. è¯´æ˜é€‰æ‹©è¯¥ç³»æ•°çš„ç†ç”±

    **ç¬¬ä¸€å±‚é¢æƒ…èŠ‚å›ºå®šç³»æ•°è¡¨ï¼ˆè¿ä¹˜ï¼‰:**
    | æƒ…èŠ‚ | ç³»æ•° | é€‚ç”¨æ¡ä»¶ |
    |------|------|----------|
    | æœªæˆå¹´äººï¼ˆ16-18å²ï¼‰| 0.70 | å·²æ»¡16å‘¨å²ä¸æ»¡18å‘¨å² |
    | æœªæˆå¹´äººï¼ˆ14-16å²ï¼‰| 0.50 | å·²æ»¡14å‘¨å²ä¸æ»¡16å‘¨å² |
    | ä»çŠ¯ï¼ˆä½œç”¨è¾ƒå°ï¼‰| 0.60 | æ˜ç¡®è¯´æ˜ä½œç”¨è¾ƒå°/æ¬¡è¦ |
    | ä»çŠ¯ï¼ˆä¸€èˆ¬ï¼‰| 0.70 | æœªæ˜ç¡®è¯´æ˜ä½œç”¨å¤§å° |
    | èƒä»çŠ¯ | 0.40 | è¢«èƒè¿«å‚åŠ çŠ¯ç½ª |
    | çŠ¯ç½ªé¢„å¤‡ | 0.40 | å‡†å¤‡å·¥å…·ã€åˆ›é€ æ¡ä»¶ |
    | çŠ¯ç½ªä¸­æ­¢ï¼ˆè‡ªåŠ¨æœ‰æ•ˆï¼‰| 0.30 | è‡ªåŠ¨æ”¾å¼ƒä¸”æœ‰æ•ˆé¿å…ç»“æœ |
    | çŠ¯ç½ªä¸­æ­¢ï¼ˆä¸€èˆ¬ï¼‰| 0.40 | è‡ªåŠ¨æ”¾å¼ƒä½†æœªæœ‰æ•ˆé¿å… |
    | çŠ¯ç½ªæœªé‚ï¼ˆæ„å¿—ä»¥å¤–ï¼‰| 0.70 | å› å®¢è§‚åŸå› æœªå¾—é€ |
    | çŠ¯ç½ªæœªé‚ï¼ˆèƒ½åŠ›ä¸è¶³ï¼‰| 0.60 | å› èƒ½åŠ›ä¸è¶³æœªå¾—é€ |
    | é™åˆ¶åˆ‘äº‹è´£ä»»èƒ½åŠ› | 0.60 | ç²¾ç¥ç—…äººåœ¨å‘ç—…æœŸé—´ |
    | åˆè‹åˆå“‘/ç›²äºº | 0.70 | ç”Ÿç†ç¼ºé™· |
    | é˜²å«è¿‡å½“ | 0.50 | æ­£å½“é˜²å«æ˜æ˜¾è¶…è¿‡å¿…è¦é™åº¦ |

    **ç¬¬äºŒå±‚é¢æƒ…èŠ‚å›ºå®šè°ƒèŠ‚è¡¨ï¼ˆåŠ å‡ï¼‰:**
    | æƒ…èŠ‚ | è°ƒèŠ‚å€¼ | é€‚ç”¨æ¡ä»¶ |
    |------|--------|----------|
    | ç´¯çŠ¯ | +25% | åˆ‘ç½šæ‰§è¡Œå®Œæ¯•5å¹´å†…å†çŠ¯ |
    | è‡ªé¦–ï¼ˆä¸»åŠ¨æŠ•æ¡ˆï¼‰| -35% | ä¸»åŠ¨æŠ•æ¡ˆå¹¶å¦‚å®ä¾›è¿° |
    | è‡ªé¦–ï¼ˆæŠ“è·åï¼‰| -25% | è¢«æŠ“è·åå¦‚å®ä¾›è¿° |
    | å¦ç™½ | -15% | å¦‚å®ä¾›è¿°ä½†éè‡ªé¦– |
    | è®¤ç½ªè®¤ç½šï¼ˆå…·ç»“ä¹¦ï¼‰| -20% | ç­¾ç½²è®¤ç½ªè®¤ç½šå…·ç»“ä¹¦ |
    | è®¤ç½ªè®¤ç½šï¼ˆå£å¤´ï¼‰| -15% | å£å¤´è®¤ç½ªè®¤ç½š |
    | ä¸€èˆ¬ç«‹åŠŸ | -15% | æ£€ä¸¾ä»–äººçŠ¯ç½ªç­‰ |
    | é‡å¤§ç«‹åŠŸ | -30% | æ£€ä¸¾é‡å¤§çŠ¯ç½ªç­‰ |
    | é€€èµƒé€€èµ”ï¼ˆå…¨éƒ¨ï¼‰| -25% | é€€èµƒ100% |
    | é€€èµƒé€€èµ”ï¼ˆéƒ¨åˆ†ï¼‰| -15% | é€€èµƒéƒ¨åˆ† |
    | å–å¾—è°…è§£ | -20% | è·å¾—è¢«å®³äººè°…è§£ |
    | åˆ‘äº‹å’Œè§£ | -35% | è¾¾æˆå’Œè§£åè®® |
    | æœ‰å‰ç§‘ï¼ˆåŒç±»ï¼‰| +20% | æœ‰åŒç±»çŠ¯ç½ªå‰ç§‘ |
    | æœ‰å‰ç§‘ï¼ˆå…¶ä»–ï¼‰| +15% | æœ‰å…¶ä»–çŠ¯ç½ªå‰ç§‘ |
    | å¤šæ¬¡çŠ¯ç½ªï¼ˆ3æ¬¡+ï¼‰| +25% | å¤šæ¬¡çŠ¯ç½ª3æ¬¡ä»¥ä¸Š |
    | å¤šæ¬¡çŠ¯ç½ªï¼ˆ2æ¬¡ï¼‰| +15% | å¤šæ¬¡çŠ¯ç½ª2æ¬¡ |
    | é€ æˆä¸¥é‡åæœ | +35% | é€ æˆä¸¥é‡ç¤¾ä¼šå½±å“ |

    ---
    **è®¡ç®—æ­¥éª¤:**

    **æ­¥éª¤1: è®¡ç®—åŸºå‡†åˆ‘**
    - ä½¿ç”¨ `calculate_base_sentence` å·¥å…·
    - æ ¹æ®æ¡ˆä»¶ä¸­çš„å…·ä½“æƒ…èŠ‚ï¼ˆå¦‚å…¥æˆ·ç›—çªƒã€ç”µä¿¡è¯ˆéª—ç­‰ï¼‰ï¼Œåœ¨è°ƒç”¨æ—¶ä¼ å…¥ `circumstances` å‚æ•°

    **æ­¥éª¤2: æƒ…èŠ‚åˆ†ç±»ä¸ç³»æ•°ç¡®å®š**
    å¯¹æ¯ä¸ªæƒ…èŠ‚ï¼š
    1. æå–å…³é”®æè¿°ï¼ˆå¹´é¾„ã€ä½œç”¨ã€æ–¹å¼ç­‰ï¼‰
    2. ä»ä¸Šè¡¨ä¸­æŸ¥æ‰¾å¯¹åº”çš„å›ºå®šç³»æ•°
    3. è¯´æ˜é€‰æ‹©ç†ç”±

    æ ¼å¼ç¤ºä¾‹ï¼š
    æƒ…èŠ‚ï¼š"æœªæˆå¹´äººï¼Œå·²æ»¡17å‘¨å²"
    â†’ åŒ¹é…ï¼šæœªæˆå¹´äººï¼ˆ16-18å²ï¼‰
    â†’ ç³»æ•°ï¼š0.70
    â†’ ç†ç”±ï¼š17å‘¨å²å±äº16-18å²åŒºé—´
    
    **æ­¥éª¤3: è°ƒç”¨è®¡ç®—å·¥å…·**
    ä½¿ç”¨ `calculate_layered_sentence_deterministic` å·¥å…·
    
    **æ­¥éª¤4: ç”ŸæˆåŒºé—´**
    - ä½¿ç”¨ `months_to_range` å·¥å…·
    - å°†æœ€ç»ˆæœˆæ•°è½¬æ¢ä¸ºåˆç†åŒºé—´(å®½åº¦6ä¸ªæœˆ)

    è¯·ä¸¥æ ¼ä½¿ç”¨ä¸Šè¡¨ä¸­çš„å›ºå®šå€¼ï¼Œä¸è¦è‡ªè¡Œè°ƒæ•´æ¯”ä¾‹ã€‚
    """
        return prompt


    def predict_task1_authoritative(self, defendant_info, case_description):
        """
        æ‰§è¡ŒTask 1:æå–é‡åˆ‘æƒ…èŠ‚ã€‚
        """
        prompt = self.build_prompt_task1_authoritative(defendant_info, case_description)
        try:
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {"role": "system",
                     "content": "ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„åˆ‘äº‹æ³•å®˜,ç²¾é€šä¸­å›½åˆ‘æ³•é‡åˆ‘æƒ…èŠ‚è®¤å®š,å¯¹ç»†èŠ‚æå…¶æ•æ„Ÿã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=self.temperature_task1,  # Task1ä½¿ç”¨è¾ƒé«˜æ¸©åº¦
                max_tokens=self.max_tokens
            )
            result_text = response.choices[0].message.content.strip()

            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ä»æ–‡æœ¬ä¸­æå–JSONæ•°ç»„
            json_match = re.search(r'\[.*?\]', result_text, re.DOTALL)
            if json_match:
                return json.loads(json_match.group(0))
            else:
                print(f"è­¦å‘Š (Task 1): æœªèƒ½åœ¨è¾“å‡ºä¸­æ‰¾åˆ°JSONæ•°ç»„ã€‚è¿”å›: {result_text}")
                return ["ç›—çªƒæ•°é¢è¾ƒå¤§"]  # Fallback
        except Exception as e:
            print(f"é”™è¯¯ (Task 1): APIè°ƒç”¨æˆ–JSONè§£æå¤±è´¥: {e}")
            return ["ç›—çªƒæ•°é¢è¾ƒå¤§"]  # Fallback

    def predict_task2_with_tools(self, sentencing_factors):
        """
        æ‰§è¡ŒTask 2:ä½¿ç”¨å·¥å…·è°ƒç”¨è¿›è¡Œåˆ‘æœŸé¢„æµ‹ã€‚
        """
        if not sentencing_factors:
            sentencing_factors = ["çŠ¯ç½ªæƒ…èŠ‚è¾ƒè½»"]

        prompt = self.build_prompt_task2_with_tools(sentencing_factors)

        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä½åˆ‘äº‹æ³•å®˜,å¿…é¡»ä½¿ç”¨æä¾›çš„è®¡ç®—å™¨å·¥å…·è¿›è¡Œç²¾ç¡®è®¡ç®—,ä¸è¦è‡ªå·±ä¼°ç®—æ•°å€¼ã€‚"},
            {"role": "user", "content": prompt}
        ]

        # å¤šè½®å¯¹è¯å¤„ç†å·¥å…·è°ƒç”¨
        max_iterations = 10
        final_range = None

        for iteration in range(max_iterations):
            try:
                response = self.client.chat.completions.create(
                    model=self.model_name,
                    messages=messages,
                    tools=SENTENCING_TOOLS,
                    temperature=self.temperature_task2,  # Task2ä½¿ç”¨è¾ƒä½æ¸©åº¦
                    max_tokens=self.max_tokens
                )

                assistant_message = response.choices[0].message

                # å¦‚æœæ²¡æœ‰å·¥å…·è°ƒç”¨,è¯´æ˜å®Œæˆ
                if not assistant_message.tool_calls:
                    content = assistant_message.content
                    print(f"  æ¨¡å‹æœ€ç»ˆå›å¤: {content}")

                    # ä»æœ€ç»ˆå“åº”ä¸­æå–åŒºé—´
                    json_match = re.search(r'\[\s*(\d+)\s*,\s*(\d+)\s*\]', content)
                    if json_match:
                        final_range = [int(json_match.group(1)), int(json_match.group(2))]
                        break
                    elif final_range:  # å¦‚æœä¹‹å‰å·²ç»è®¡ç®—å‡ºäº†åŒºé—´
                        break
                    else:
                        print(f"è­¦å‘Š: æœªæ‰¾åˆ°åˆ‘æœŸåŒºé—´,ä½¿ç”¨é»˜è®¤å€¼")
                        return [6, 12]

                # æ·»åŠ åŠ©æ‰‹æ¶ˆæ¯
                messages.append({
                    "role": "assistant",
                    "content": assistant_message.content,
                    "tool_calls": [
                        {
                            "id": tc.id,
                            "type": "function",
                            "function": {
                                "name": tc.function.name,
                                "arguments": tc.function.arguments
                            }
                        } for tc in assistant_message.tool_calls
                    ]
                })

                # æ‰§è¡Œå·¥å…·è°ƒç”¨
                for tool_call in assistant_message.tool_calls:
                    function_name = tool_call.function.name
                    function_args = json.loads(tool_call.function.arguments)

                    print(f"  ğŸ”§ è°ƒç”¨å·¥å…·: {function_name}")
                    print(f"     å‚æ•°: {json.dumps(function_args, ensure_ascii=False)}")

                    # æ‰§è¡Œå·¥å…·
                    function_response = execute_tool_call(function_name, function_args)
                    print(f"     ç»“æœ: {function_response}")

                    # æ£€æŸ¥æ˜¯å¦æ˜¯æœ€ç»ˆçš„åŒºé—´ç»“æœ
                    if function_name == "months_to_range":
                        try:
                            result_data = json.loads(function_response)
                            if "range" in result_data:
                                final_range = result_data["range"]
                        except:
                            pass

                    # æ·»åŠ å·¥å…·å“åº”
                    messages.append({
                        "role": "tool",
                        "tool_call_id": tool_call.id,
                        "content": function_response
                    })

            except Exception as e:
                print(f"å·¥å…·è°ƒç”¨é”™è¯¯: {e}")
                return [6, 12]  # Fallback

        if final_range:
            return final_range
        else:
            print("è­¦å‘Š: è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ä½†æœªè·å¾—ç»“æœ")
            return [6, 12]  # Fallback

    def process_all_data(self, preprocessed_data, output_file):
        """
        ä¸»å¤„ç†æµç¨‹:éå†æ‰€æœ‰æ•°æ®,æ‰§è¡Œä¸¤é˜¶æ®µé¢„æµ‹,å¹¶ä¿å­˜ç»“æœã€‚
        """
        results = []

        for idx, item in enumerate(preprocessed_data):
            print(f"\n{'=' * 60}")
            print(f"å¤„ç†ç¬¬ {idx + 1}/{len(preprocessed_data)} æ¡æ•°æ® (ID: {item['id']})")
            print(f"{'=' * 60}")

            answer1, answer2 = [], []
            try:
                # ç¬¬ä¸€æ­¥:è°ƒç”¨æƒå¨ç‰ˆ Task 1 é¢„æµ‹,æå–é‡åˆ‘æƒ…èŠ‚
                print("\nã€æ­¥éª¤1: æå–é‡åˆ‘æƒ…èŠ‚ã€‘")
                answer1 = self.predict_task1_authoritative(
                    item['defendant_info'],
                    item['case_description']
                )
                print(f"âœ“ æå–åˆ°çš„æƒ…èŠ‚: {answer1}")

                # ç¬¬äºŒæ­¥:ä½¿ç”¨å·¥å…·è°ƒç”¨è¿›è¡Œåˆ‘æœŸé¢„æµ‹
                print("\nã€æ­¥éª¤2: ä½¿ç”¨å·¥å…·è®¡ç®—åˆ‘æœŸã€‘")
                answer2 = self.predict_task2_with_tools(
                    answer1,
                )
                print(f"âœ“ é¢„æµ‹åˆ‘æœŸåŒºé—´: {answer2}")

            except Exception as e:
                print(f"!!! å¤„ç†ID {item['id']} æ—¶å‘ç”ŸæœªçŸ¥ä¸¥é‡é”™è¯¯: {e}")
                answer1 = answer1 if answer1 else ["ç›—çªƒæ•°é¢è¾ƒå¤§"]
                answer2 = answer2 if answer2 else [6, 12]

            result = {
                "id": item['id'],
                "answer1": answer1,
                "answer2": answer2
            }
            results.append(result)

            print(f"\nã€æœ€ç»ˆç»“æœã€‘")
            print(f"  ç­”æ¡ˆ1 (æƒ…èŠ‚æå–): {answer1}")
            print(f"  ç­”æ¡ˆ2 (åˆ‘æœŸé¢„æµ‹): {answer2}")

            # æ¯å¤„ç†10æ¡æ•°æ®ä¿å­˜ä¸€æ¬¡,é˜²æ­¢æ„å¤–ä¸­æ–­ä¸¢å¤±è¿›åº¦
            if (idx + 1) % 10 == 0:
                print(f"\n--- è¿›åº¦ä¿å­˜:å·²å¤„ç† {idx + 1} æ¡æ•°æ® ---")
                self._save_results(results, output_file)

        # æœ€ç»ˆä¿å­˜æ‰€æœ‰ç»“æœ
        self._save_results(results, output_file)
        print(f"\næ‰€æœ‰æ•°æ®å¤„ç†å®Œæˆ,ç»“æœå·²ä¿å­˜è‡³: {output_file}")
        return results

    def process_fact_data(self, fact_data, output_file):
        """
        å¤„ç†factæ ¼å¼çš„æ•°æ®ï¼ˆæ–°æ ¼å¼ï¼‰
        """
        results = []

        for idx, item in enumerate(fact_data):
            print(f"\n{'=' * 60}")
            print(f"å¤„ç†ç¬¬ {idx + 1}/{len(fact_data)} æ¡æ•°æ® (ID: {item['id']})")
            print(f"{'=' * 60}")

            answer1, answer2 = [], []
            try:
                # ç¬¬ä¸€æ­¥:è°ƒç”¨æƒå¨ç‰ˆ Task 1 é¢„æµ‹,æå–é‡åˆ‘æƒ…èŠ‚
                print("\nã€æ­¥éª¤1: æå–é‡åˆ‘æƒ…èŠ‚ã€‘")
                answer1 = self.predict_task1_authoritative(
                    "",  # è¢«å‘Šäººä¿¡æ¯ä¸ºç©º
                    item['fact']  # ä½¿ç”¨factå­—æ®µä½œä¸ºæ¡ˆæƒ…æè¿°
                )
                print(f"âœ“ æå–åˆ°çš„æƒ…èŠ‚: {answer1}")

                # ç¬¬äºŒæ­¥:ä½¿ç”¨å·¥å…·è°ƒç”¨è¿›è¡Œåˆ‘æœŸé¢„æµ‹
                print("\nã€æ­¥éª¤2: ä½¿ç”¨å·¥å…·è®¡ç®—åˆ‘æœŸã€‘")
                answer2 = self.predict_task2_with_tools(
                    answer1,
                )
                print(f"âœ“ é¢„æµ‹åˆ‘æœŸåŒºé—´: {answer2}")

            except Exception as e:
                print(f"!!! å¤„ç†ID {item['id']} æ—¶å‘ç”ŸæœªçŸ¥ä¸¥é‡é”™è¯¯: {e}")
                answer1 = answer1 if answer1 else ["ç›—çªƒæ•°é¢è¾ƒå¤§"]
                answer2 = answer2 if answer2 else [6, 12]

            result = {
                "id": item['id'],
                "answer1": answer1,
                "answer2": answer2
            }
            results.append(result)

            print(f"\nã€æœ€ç»ˆç»“æœã€‘")
            print(f"  ç­”æ¡ˆ1 (æƒ…èŠ‚æå–): {answer1}")
            print(f"  ç­”æ¡ˆ2 (åˆ‘æœŸé¢„æµ‹): {answer2}")

            # æ¯å¤„ç†10æ¡æ•°æ®ä¿å­˜ä¸€æ¬¡,é˜²æ­¢æ„å¤–ä¸­æ–­ä¸¢å¤±è¿›åº¦
            if (idx + 1) % 10 == 0:
                print(f"\n--- è¿›åº¦ä¿å­˜:å·²å¤„ç† {idx + 1} æ¡æ•°æ® ---")
                self._save_results(results, output_file)

        # æœ€ç»ˆä¿å­˜æ‰€æœ‰ç»“æœ
        self._save_results(results, output_file)
        print(f"\næ‰€æœ‰æ•°æ®å¤„ç†å®Œæˆ,ç»“æœå·²ä¿å­˜è‡³: {output_file}")
        return results

    def _save_results(self, results, output_file):
        """
        å°†ç»“æœä»¥jsonlæ ¼å¼ä¿å­˜åˆ°æ–‡ä»¶ã€‚
        """
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                for result in results:
                    f.write(json.dumps(result, ensure_ascii=False) + '\n')
        except IOError as e:
            print(f"é”™è¯¯:æ— æ³•å†™å…¥æ–‡ä»¶ {output_file}ã€‚è¯·æ£€æŸ¥æƒé™æˆ–è·¯å¾„ã€‚é”™è¯¯ä¿¡æ¯: {e}")


def load_preprocessed_data(preprocessed_file):
    """
    åŠ è½½å¹¶éªŒè¯é¢„å¤„ç†åçš„æ•°æ®æ–‡ä»¶ã€‚
    """
    if not os.path.exists(preprocessed_file):
        raise FileNotFoundError(f"é”™è¯¯:é¢„å¤„ç†æ–‡ä»¶ä¸å­˜åœ¨: {preprocessed_file}\nè¯·ç¡®ä¿æ–‡ä»¶è·¯å¾„æ­£ç¡®ã€‚")

    print(f"æ­£åœ¨åŠ è½½é¢„å¤„ç†æ•°æ®: {preprocessed_file}")
    with open(preprocessed_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    print(f"âœ“ æˆåŠŸåŠ è½½ {len(data)} æ¡é¢„å¤„ç†æ•°æ®")
    return data


def load_fact_data(fact_file):
    """
    åŠ è½½factæ ¼å¼çš„æ•°æ®æ–‡ä»¶ã€‚
    """
    if not os.path.exists(fact_file):
        raise FileNotFoundError(f"é”™è¯¯:æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {fact_file}\nè¯·ç¡®ä¿æ–‡ä»¶è·¯å¾„æ­£ç¡®ã€‚")

    print(f"æ­£åœ¨åŠ è½½factæ•°æ®: {fact_file}")
    data = []
    with open(fact_file, 'r', encoding='utf-8') as f:
        for line in f:
            if line.strip():
                data.append(json.loads(line.strip()))
    print(f"âœ“ æˆåŠŸåŠ è½½ {len(data)} æ¡factæ•°æ®")
    return data


def main():
    """
    ä¸»å‡½æ•°:åˆå§‹åŒ–å¹¶è¿è¡Œæ•´ä¸ªé¢„æµ‹æµç¨‹ã€‚
    """
    # é…ç½®æ–‡ä»¶è·¯å¾„
    preprocessed_file = "extracted_info_fusai1.json"
    fact_file = "data/task6_fusai.jsonl"
    output_file = "submission_with_tools_fact_1112_deepseek.jsonl"

    print("=" * 60)
    print(" æ³•å¾‹é‡åˆ‘é¢„æµ‹ç³»ç»Ÿ (å·¥å…·è°ƒç”¨ç‰ˆ) ")
    print("=" * 60)

    # æ£€æŸ¥factæ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if os.path.exists(fact_file):
        print(f"æ£€æµ‹åˆ°factæ ¼å¼æ•°æ®æ–‡ä»¶: {fact_file}")
        try:
            fact_data = load_fact_data(fact_file)
        except Exception as e:
            print(f"\nåŠ è½½factæ•°æ®æ—¶å‘ç”Ÿè‡´å‘½é”™è¯¯: {e}")
            return
        
        print("\n" + "=" * 60)
        print("å¼€å§‹æ¨¡å‹é¢„æµ‹...")
        print("=" * 60 + "\n")

        predictor = SentencingPredictor()
        results = predictor.process_fact_data(fact_data, output_file)

        print("\n" + "=" * 60)
        print("âœ“ ä»»åŠ¡å®Œæˆ!")
        print(f"âœ“ å…±å¤„ç† {len(results)} æ¡æ•°æ®")
        print(f"âœ“ ç»“æœå·²æˆåŠŸä¿å­˜è‡³: {output_file}")
        print("=" * 60)
        return

    # å¦‚æœæ²¡æœ‰factæ–‡ä»¶ï¼Œåˆ™å°è¯•åŠ è½½é¢„å¤„ç†æ–‡ä»¶
    try:
        preprocessed_data = load_preprocessed_data(preprocessed_file)
    except Exception as e:
        print(f"\nåŠ è½½æ•°æ®æ—¶å‘ç”Ÿè‡´å‘½é”™è¯¯: {e}")
        return

    print("\n" + "=" * 60)
    print("å¼€å§‹æ¨¡å‹é¢„æµ‹...")
    print("=" * 60 + "\n")

    predictor = SentencingPredictor()
    results = predictor.process_all_data(preprocessed_data, output_file)

    print("\n" + "=" * 60)
    print("âœ“ ä»»åŠ¡å®Œæˆ!")
    print(f"âœ“ å…±å¤„ç† {len(results)} æ¡æ•°æ®")
    print(f"âœ“ ç»“æœå·²æˆåŠŸä¿å­˜è‡³: {output_file}")
    print("=" * 60)


if __name__ == "__main__":
    main()